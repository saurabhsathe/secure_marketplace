{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caa8ec82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\16692\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string, nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb24c008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \n",
       "0  Love this!  Well made, sturdy, and very comfor...  \n",
       "1  love it, a great upgrade from the original.  I...  \n",
       "2  This pillow saved my back. I love the look and...  \n",
       "3  Missing information on how to use it, but it i...  \n",
       "4  Very nice set. Good quality. We have had the s...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fake reviews dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2165040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a117ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    nopunc = [w for w in text if w not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return  ' '.join([word for word in nopunc.split() if word.lower() not in stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94a3ffb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty',\n",
       " 'Love Well made sturdy comfortable love itVery pretty')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_'][0], clean_text(df['text_'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fbed0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_'] = df['text_'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f595971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return ' '.join([word for word in word_tokenize(text) if word not in stopwords.words('english') and not word.isdigit() and word not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68e8efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_'][:10000] = df['text_'][:10000].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21b10ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_'][10001:20000] = df['text_'][10001:20000].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "154f3e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_'][20001:30000] = df['text_'][20001:30000].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c030fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_'][30001:40000] = df['text_'][30001:40000].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b209e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_'][40001:40432] = df['text_'][40001:40432].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abaa3298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_'] = df['text_'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0d8b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "df['text_'] = df['text_'].apply(lambda x: stem_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97bfceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "df[\"text_\"] = df[\"text_\"].apply(lambda text: lemmatize_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3908e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love well made sturdi comfort i love veri pretti</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love great upgrad origin i 've mine coupl year</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>thi pillow save back i love look feel pillow</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>miss inform use great product price i</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>veri nice set good qualiti we set two month</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                              text_  length  \n",
       "0  love well made sturdi comfort i love veri pretti      75  \n",
       "1    love great upgrad origin i 've mine coupl year      80  \n",
       "2      thi pillow save back i love look feel pillow      67  \n",
       "3             miss inform use great product price i      81  \n",
       "4       veri nice set good qualiti we set two month      85  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a554e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38993f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = df['text_'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f891773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(review):\n",
    "    nopunc = [char for char in review if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4fa11a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary: 34450\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=text_process)\n",
    "bow_transformer.fit(df['text_'])\n",
    "print(\"Total Vocabulary:\",len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dec4255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('bow.pkl', 'wb') as outp:\n",
    "    pickle.dump(bow_transformer, outp, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f7b0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_reviews = bow_transformer.transform(df['text_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bf3f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(bow_reviews).to_csv(\"bagofwords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e749fc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Bag of Words Transformer for the entire reviews corpus: (40432, 34450)\n",
      "Amount of non zero values in the bag of words model: 1013898\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Bag of Words Transformer for the entire reviews corpus:\",bow_reviews.shape)\n",
    "print(\"Amount of non zero values in the bag of words model:\",bow_reviews.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31f1c942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40432x34450 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1013898 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_transformer.fit(bow_reviews)\n",
    "\n",
    "with open('tfidf.pkl', 'wb') as outpidf:\n",
    "    pickle.dump(tfidf_transformer, outpidf, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "227ac5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (40432, 34450)\n",
      "No. of Dimensions: 2\n"
     ]
    }
   ],
   "source": [
    "tfidf_reviews = tfidf_transformer.transform(bow_reviews)\n",
    "print(\"Shape:\",tfidf_reviews.shape)\n",
    "print(\"No. of Dimensions:\",tfidf_reviews.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bdceb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_train, review_test, label_train, label_test = train_test_split(df['text_'],df['label'],test_size=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a088a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99e52e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function text_process at 0x000002783CAFE790>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(review_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "361d807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = pipeline.predict(review_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print('Classification Report:',classification_report(label_test,rfc_pred))\n",
    "print('Confusion Matrix:',confusion_matrix(label_test,rfc_pred))\n",
    "print('Accuracy Score:',accuracy_score(label_test,rfc_pred))\n",
    "print('Model Prediction Accuracy:',str(np.round(accuracy_score(label_test,rfc_pred)*100,2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c111aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('pipeline.pkl', 'wb') as out_pipeline:\n",
    "    pickle.dump(pipeline, out_pipeline, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2474534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline2.sav']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(pipeline,\"pipeline2.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc9030b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(analyzer=text_process)\n",
    "tfidf = TfidfTransformer()\n",
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "51d5283c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_train = cv.fit_transform(review_train)\n",
    "review_train = tfidf.fit_transform(review_train)\n",
    "classifier.fit(review_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3754d701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.81      0.88      0.84      7071\n",
      "          OR       0.87      0.79      0.83      7081\n",
      "\n",
      "    accuracy                           0.84     14152\n",
      "   macro avg       0.84      0.84      0.84     14152\n",
      "weighted avg       0.84      0.84      0.84     14152\n",
      "\n",
      "Confusion Matrix: [[6254  817]\n",
      " [1484 5597]]\n",
      "Accuracy Score: 0.837408140192199\n",
      "Model Prediction Accuracy: 83.74%\n"
     ]
    }
   ],
   "source": [
    "review_test = cv.transform(review_test)\n",
    "review_test = tfidf.transform(review_test)\n",
    "rfc_pred = classifier.predict(review_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print('Classification Report:',classification_report(label_test,rfc_pred))\n",
    "print('Confusion Matrix:',confusion_matrix(label_test,rfc_pred))\n",
    "print('Accuracy Score:',accuracy_score(label_test,rfc_pred))\n",
    "print('Model Prediction Accuracy:',str(np.round(accuracy_score(label_test,rfc_pred)*100,2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d99ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cv_final.pkl', 'wb') as out_pipeline:\n",
    "    pickle.dump(cv, out_pipeline, pickle.HIGHEST_PROTOCOL)\n",
    "with open('tfidf_final.pkl', 'wb') as out_pipeline:\n",
    "    pickle.dump(tfidf, out_pipeline, pickle.HIGHEST_PROTOCOL)\n",
    "with open('classifier.pkl', 'wb') as out_pipeline:\n",
    "    pickle.dump(classifier, out_pipeline, pickle.HIGHEST_PROTOCOL)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
